{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5188c5b-ae79-40c8-a2ab-c76d910900a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /home/jovyan/data/red-wine-quality-cortez-et-al-2009\n",
      "Skipping download...\n",
      "You can now access the dataset files from: /home/jovyan/data/red-wine-quality-cortez-et-al-2009\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "dataset_id = \"uciml/red-wine-quality-cortez-et-al-2009\"\n",
    "\n",
    "\n",
    "local_dataset_name = dataset_id.split('/')[-1] # Uses the last part of the ID\n",
    "\n",
    "# Check if dataset already exists in destination\n",
    "destination_path = f\"/home/jovyan/data/{local_dataset_name}\"\n",
    "if os.path.exists(destination_path) and os.listdir(destination_path):\n",
    "    print(f\"Dataset already exists at {destination_path}\")\n",
    "    print(\"Skipping download...\")\n",
    "else:\n",
    "    print(f\"Dataset not found locally. Downloading {dataset_id}...\")\n",
    "\n",
    "\n",
    "    print(f\"Downloading dataset: {dataset_id}\")\n",
    "\n",
    "    # downloads to a cache location inside the container\n",
    "    download_path = kagglehub.dataset_download(dataset_id)\n",
    "    print(f\"Dataset downloaded to temporary path in container: {download_path}\")\n",
    "\n",
    "    # destination path in mounted data volume - inside the 'data' folder on local \n",
    "    destination_path = f\"/home/jovyan/data/{local_dataset_name}\"\n",
    "    print(f\"Copying dataset to shared data volume: {destination_path}\")\n",
    "\n",
    "    # Ensure the destination directory exists \n",
    "    os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "    # Copy the contents of the downloaded dataset directory to data volume\n",
    "    # This makes the data persistent and accessible from host and other services\n",
    "    for item in os.listdir(download_path):\n",
    "        s = os.path.join(download_path, item)\n",
    "        d = os.path.join(destination_path, item)\n",
    "        if os.path.isdir(s):\n",
    "            shutil.copytree(s, d, symlinks=False, ignore=None, dirs_exist_ok=True)\n",
    "        else:\n",
    "            shutil.copy2(s, d)\n",
    "\n",
    "    print(f\"Dataset '{dataset_id}' successfully copied to {destination_path} in your shared volume.\")\n",
    "print(f\"You can now access the dataset files from: {destination_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef36c95-81dc-45b5-a91a-6134692ce15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing files in /home/jovyan/data/red-wine-quality-cortez-et-al-2009:\n",
      "red-wine-quality-cortez-et-al-2009/\n",
      "    winequality-red.csv\n",
      "\n",
      "Loading data from: /home/jovyan/data/red-wine-quality-cortez-et-al-2009/winequality-red.csv\n",
      "\n",
      "Available columns in the dataset:\n",
      "0: fixed acidity\n",
      "1: volatile acidity\n",
      "2: citric acid\n",
      "3: residual sugar\n",
      "4: chlorides\n",
      "5: free sulfur dioxide\n",
      "6: total sulfur dioxide\n",
      "7: density\n",
      "8: pH\n",
      "9: sulphates\n",
      "10: alcohol\n",
      "11: quality\n",
      "\n",
      "Please set target_column variable above and run this cell again.\n",
      "Example: target_column = 'column_name'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Waiting for target column selection...",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Waiting for target column selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Import Libraries and Load Data ---\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import wandb\n",
    "import os\n",
    "import cProfile # For basic profiling\n",
    "import pstats # For processing profiling results\n",
    "import io # For capturing profiling output\n",
    "\n",
    "# Define the name of the dataset directory in your shared data volume\n",
    "# This should match the local_dataset_name used in the download step\n",
    "# Use the local_dataset_name from cell 1 - no need to redefine it here\n",
    "# local_dataset_name = \"red-wine-quality-cortez-et-al-2009\" # Example dataset name\n",
    "dataset_path = f\"/home/jovyan/data/{local_dataset_name}\"\n",
    "\n",
    "# Define the name of the dataset file within that directory\n",
    "# You might need to check the contents of the downloaded dataset to find the correct file name\n",
    "# For the red wine quality dataset, let's assume it's 'winequality-red.csv' or similar.\n",
    "# You might need to adjust this based on the actual dataset structure.\n",
    "# Let's list files in the downloaded directory to be sure\n",
    "print(f\"Listing files in {dataset_path}:\")\n",
    "try:\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        level = root.replace(dataset_path, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f'{subindent}{f}')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Directory not found: {dataset_path}. Please ensure the dataset was downloaded and copied correctly.\")\n",
    "    # Exit or handle the error appropriately if the directory is not found\n",
    "\n",
    "# Assuming the data file is named 'winequality-red.csv' within the downloaded directory\n",
    "# Adjust this path based on the actual file name and structure\n",
    "# Find the first CSV file in the dataset directory\n",
    "csv_files = [f for f in os.listdir(dataset_path) if f.endswith('.csv')]\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV files found in {dataset_path}\")\n",
    "if len(csv_files) > 1:\n",
    "    print(f\"Warning: Multiple CSV files found. Using the first one: {csv_files[0]}\")\n",
    "\n",
    "# Load the data\n",
    "data_file_path = os.path.join(dataset_path, csv_files[0])\n",
    "print(f\"\\nLoading data from: {data_file_path}\")\n",
    "df = pd.read_csv(data_file_path)\n",
    "\n",
    "# Display available columns and prompt for target\n",
    "print(\"\\nAvailable columns in the dataset:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "# Create a flag file to check if target has been selected\n",
    "target_flag_file = os.path.join(dataset_path, '.target_selected')\n",
    "target_column = 'quality'\n",
    "if not os.path.exists(target_flag_file):\n",
    "    print(\"\\nPlease set target_column variable above and run this cell again.\")\n",
    "    print(\"Example: target_column = 'column_name'\")\n",
    "    # Create an empty flag file to indicate we need target selection\n",
    "    with open(target_flag_file, 'w') as f:\n",
    "        pass\n",
    "    raise SystemExit(\"Waiting for target column selection...\")\n",
    "\n",
    "# If target_column is defined and valid, save it to the flag file\n",
    "try:\n",
    "    if target_column in df.columns:\n",
    "        with open(target_flag_file, 'w') as f:\n",
    "            f.write(target_column)\n",
    "        print(f\"\\nTarget column '{target_column}' has been saved.\")\n",
    "    else:\n",
    "        os.remove(target_flag_file)  # Remove flag file if target is invalid\n",
    "        raise ValueError(f\"Selected target column '{target_column}' not found in dataset columns\")\n",
    "except NameError:\n",
    "    os.remove(target_flag_file)  # Remove flag file if target_column not defined\n",
    "    raise NameError(\"target_column variable not defined. Please define it and run again.\")\n",
    "\n",
    "\n",
    "\n",
    "# data_file_path = os.path.join(dataset_path, 'winequality-red.csv') # ** ADJUST THIS **\n",
    "# Check if target_column is defined and valid\n",
    "try:\n",
    "    with open(target_flag_file, 'r') as f:\n",
    "        target_column = f.read().strip()\n",
    "    if not target_column:\n",
    "        raise ValueError(\"Target column not found in flag file\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(data_file_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(\"Dataset shape:\", df.shape)\n",
    "    print(\"Dataset columns:\", df.columns.tolist())\n",
    "    print(\"Dataset head:\\n\", df.head())\n",
    "\n",
    "    # Verify target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in the dataset.\")\n",
    "\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Data split into training ({X_train.shape[0]} samples) and testing ({X_test.shape[0]} samples).\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {data_file_path}. Please check the file name and path.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error during data preparation: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during data loading or preparation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a0745-05b9-44a8-a82d-6be6d2f23462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: MLflow and W&B Setup, Profiling Start ---\n",
    "\n",
    "# Ensure MLflow tracking URI is set (should be from environment variable)\n",
    "# mlflow.set_tracking_uri(\"http://mlflow:5000\") # This should be set by docker-compose env var\n",
    "\n",
    "# Set the MLflow experiment name\n",
    "mlflow_experiment_name = f\"{local_dataset_name}_Decision_Tree\"\n",
    "print(f\"\\nSetting MLflow experiment: {mlflow_experiment_name}\")\n",
    "mlflow.set_experiment(mlflow_experiment_name)\n",
    "\n",
    "# Start a new MLflow run\n",
    "mlflow_run = mlflow.start_run()\n",
    "print(f\"Started MLflow run with ID: {mlflow_run.info.run_id}\")\n",
    "\n",
    "# W&B: Initialize a new run\n",
    "# The project name helps organize runs in the W&B UI\n",
    "# The WANDB_DIR environment variable in docker-compose.yml ensures data goes to the shared volume\n",
    "wandb_project_name = f\"kaggle_{local_dataset_name}\"\n",
    "wandb_run_name = \"decision-tree-training\"\n",
    "print(f\"Initializing W&B run: Project='{wandb_project_name}', Name='{wandb_run_name}'\")\n",
    "wandb.init(project=wandb_project_name, name=wandb_run_name)\n",
    "print(f\"Started W&B run with ID: {wandb.run.id}\")\n",
    "\n",
    "\n",
    "# Define model parameters\n",
    "max_depth = 10 # Example hyperparameter\n",
    "random_state = 42\n",
    "\n",
    "# Log parameters to MLflow and W&B\n",
    "print(\"Logging parameters to MLflow and W&B...\")\n",
    "mlflow.log_param(\"max_depth\", max_depth)\n",
    "mlflow.log_param(\"random_state\", random_state)\n",
    "wandb.config.max_depth = max_depth\n",
    "wandb.config.random_state = random_state\n",
    "print(\"Parameters logged.\")\n",
    "\n",
    "# --- Start Profiling ---\n",
    "# Profiling the training process to understand where time is spent\n",
    "print(\"Starting profiling...\")\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "\n",
    "# --- Cell 4: Model Training ---\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "print(\"Training Decision Tree model...\")\n",
    "model = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "\n",
    "# --- Cell 5: Profiling Stop and Processing ---\n",
    "\n",
    "# --- Stop Profiling ---\n",
    "print(\"Stopping profiling...\")\n",
    "pr.disable()\n",
    "print(\"Profiling stopped.\")\n",
    "\n",
    "# Process profiling results\n",
    "print(\"Processing profiling results...\")\n",
    "s = io.StringIO()\n",
    "sortby = 'cumulative' # Sort results by cumulative time\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats()\n",
    "profiling_output = s.getvalue()\n",
    "print(\"Profiling results processed.\")\n",
    "\n",
    "# Print a snippet of profiling results (optional)\n",
    "print(\"\\n--- Profiling Snippet (Top 10 by Cumulative Time) ---\")\n",
    "print('\\n'.join(profiling_output.splitlines()[:15])) # Print header and top few lines\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- Cell 6: Model Evaluation and Metric Logging ---\n",
    "\n",
    "# Make predictions on the test set\n",
    "print(\"Making predictions on the test set...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predictions made.\")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print(\"Calculating evaluation metrics...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0) # Use weighted average for multi-class\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Metrics calculated.\")\n",
    "\n",
    "# Log metrics to MLflow and W&B\n",
    "print(\"Logging metrics to MLflow and W&B...\")\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.log_metric(\"precision\", precision)\n",
    "mlflow.log_metric(\"recall\", recall)\n",
    "mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "wandb.log({\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1\n",
    "})\n",
    "print(\"Metrics logged.\")\n",
    "\n",
    "# --- Cell 7: Model and Artifact Logging ---\n",
    "\n",
    "# Log the trained model to MLflow\n",
    "print(\"Logging model with MLflow...\")\n",
    "# The model will be saved under the 'artifacts' directory of the MLflow run\n",
    "mlflow.sklearn.log_model(model, \"decision_tree_model\")\n",
    "print(\"Model logged to MLflow.\")\n",
    "\n",
    "# Log profiling results as an artifact to MLflow and W&B\n",
    "print(\"Logging profiling results as artifacts...\")\n",
    "profiling_output_filename = \"profiling_results.txt\"\n",
    "with open(profiling_output_filename, \"w\") as f:\n",
    "    f.write(profiling_output)\n",
    "\n",
    "mlflow.log_artifact(profiling_output_filename)\n",
    "wandb.save(profiling_output_filename)\n",
    "\n",
    "print(f\"Profiling results logged as artifact: {profiling_output_filename}\")\n",
    "\n",
    "# Clean up the temporary profiling file\n",
    "os.remove(profiling_output_filename)\n",
    "print(f\"Temporary profiling file removed: {profiling_output_filename}\")\n",
    "\n",
    "\n",
    "# --- Cell 8: End Runs ---\n",
    "\n",
    "# End the MLflow run\n",
    "print(\"Ending MLflow run...\")\n",
    "mlflow.end_run()\n",
    "print(\"MLflow run ended.\")\n",
    "\n",
    "# End the W&B run\n",
    "print(\"Ending W&B run...\")\n",
    "wandb.finish()\n",
    "print(\"W&B run finished.\")\n",
    "\n",
    "print(\"\\nExperiment complete. Check MLflow UI at http://localhost:5000 and W&B UI at http://localhost:8082\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
